{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16641434-9c23-46ba-90a4-5f9c2d5e1553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.6442456245422363, 5.135899066925049, 6.6543192863464355, 8.053271293640137, 9.221745491027832]\n",
      "[9.019563674926758, 10.173517227172852, 10.826087951660156, 11.196292877197266, 11.374700546264648]\n",
      "[8.966129302978516, 10.64471435546875, 11.203575134277344, 11.390665054321289, 11.45847225189209]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# Sample data (variable-length input/output)\n",
    "data = [\n",
    "    {\"input\": [1, 2, 3], \"output\": [4, 5]},\n",
    "    {\"input\": [4, 5, 6, 7, 8], \"output\": [9, 10, 11]},\n",
    "    {\"input\": [7, 8], \"output\": [9, 10, 11, 12, 13]},\n",
    "]\n",
    "\n",
    "# Encoder Class\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(1, hidden_size, batch_first=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_size)\n",
    "        _, (hidden, cell) = self.lstm(x)\n",
    "        return hidden, cell\n",
    "\n",
    "# Decoder Class\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(1, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: (batch_size, 1, input_size)\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        prediction = self.fc(output)\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "# Combined Seq2Seq Model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, src, trg=None, max_pred_len=5):\n",
    "        # Encoder pass\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        # Prepare decoder\n",
    "        batch_size = src.shape[0]\n",
    "        decoder_input = src[:, -1:, :]  # Last input as first decoder input\n",
    "        \n",
    "        # Determine prediction length\n",
    "        pred_len = len(trg[0]) if trg is not None else max_pred_len\n",
    "        \n",
    "        # Store outputs\n",
    "        outputs = []\n",
    "        \n",
    "        # Decoder pass\n",
    "        for t in range(pred_len):\n",
    "            decoder_output, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
    "            outputs.append(decoder_output.squeeze(0))\n",
    "            \n",
    "            # Teacher forcing (if training)\n",
    "            if trg is not None and random.random() < 0.5:\n",
    "                decoder_input = trg[:, t:t+1, :]\n",
    "            else:\n",
    "                decoder_input = decoder_output\n",
    "        \n",
    "        return torch.cat(outputs, dim=0).unsqueeze(0)\n",
    "\n",
    "# Helper function to prepare samples\n",
    "def prepare_sample(sample):\n",
    "    input_tensor = torch.tensor(sample[\"input\"], dtype=torch.float32).unsqueeze(0).unsqueeze(-1)\n",
    "    output_tensor = torch.tensor(sample[\"output\"], dtype=torch.float32).unsqueeze(0).unsqueeze(-1)\n",
    "    return input_tensor, output_tensor\n",
    "\n",
    "# Initialize models\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "# Training setup\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    random.shuffle(data)\n",
    "    total_loss = 0\n",
    "    \n",
    "    for sample in data:\n",
    "        src, trg = prepare_sample(sample)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(src, trg=trg)\n",
    "        loss = criterion(pred, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    #print(f\"Epoch {epoch}, Loss: {total_loss / len(data)}\")\n",
    "\n",
    "# Prediction function\n",
    "def predict(model, input_seq, max_len=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).unsqueeze(-1)\n",
    "        pred = model(src, max_pred_len=max_len)\n",
    "        return pred.squeeze().tolist()\n",
    "\n",
    "# Test predictions\n",
    "print(predict(model, [1, 2, 3], 2))       # Should output ~[4, 5]\n",
    "print(predict(model, [4, 5, 6, 7, 8])) # Should output ~[9, 10, 11]\n",
    "print(predict(model, [7, 8]))          # Should output ~[9, 10, 11, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "417553f4-4d2a-4006-b84e-6927b15189b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.6442456245422363, 5.135899066925049]\n",
      "[9.019563674926758, 10.173517227172852, 10.826087951660156, 11.196292877197266, 11.374700546264648]\n",
      "[8.966129302978516, 10.64471435546875, 11.203575134277344, 11.390665054321289, 11.45847225189209]\n"
     ]
    }
   ],
   "source": [
    "# Test predictions\n",
    "print(predict(model, [1, 2, 3], 2))       # Should output ~[4, 5]\n",
    "print(predict(model, [4, 5, 6, 7, 8])) # Should output ~[9, 10, 11]\n",
    "print(predict(model, [7, 8]))          # Should output ~[9, 10, 11, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaac28c-92fc-4e44-a86e-c6d2cca93405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
